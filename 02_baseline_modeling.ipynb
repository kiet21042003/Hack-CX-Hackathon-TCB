{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466cfca3",
   "metadata": {},
   "source": [
    "# II. Baseline Modeling: Customer Product Adoption Prediction\n",
    "\n",
    "## Objectives\n",
    "- Establish baseline model performance benchmarks\n",
    "- Compare multiple algorithms for product adoption prediction\n",
    "- Implement proper evaluation framework with business metrics\n",
    "- Create model interpretation and feature importance analysis\n",
    "- Prepare foundation for advanced modeling techniques\n",
    "\n",
    "## Modeling Strategy\n",
    "We'll implement several baseline models:\n",
    "1. **Logistic Regression** - Linear baseline with interpretability\n",
    "2. **Random Forest** - Ensemble method for feature importance\n",
    "3. **XGBoost** - Gradient boosting for performance\n",
    "4. **Neural Network** - Deep learning baseline\n",
    "5. **Naive Bayes** - Probabilistic baseline\n",
    "\n",
    "## Evaluation Framework\n",
    "- **Primary Metrics**: Precision@K, Recall@K, F1-Score\n",
    "- **Business Metrics**: Conversion Lift, Revenue Impact\n",
    "- **Statistical Tests**: McNemar's test for model comparison\n",
    "- **Cross-Validation**: Time-based splits to prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449a8e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è XGBoost not available. Install with: pip install xgboost\n",
      "üöÄ Baseline Modeling Environment Initialized\n",
      "XGBoost Available: False\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import joblib  # For memory-efficient model serialization\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, roc_curve, average_precision_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Advanced ML Libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"üöÄ Baseline Modeling Environment Initialized\")\n",
    "print(f\"XGBoost Available: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2da29",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99dabe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LOADING PROCESSED DATASETS\n",
      "==================================================\n",
      "‚úì Loaded processed adoption logs: (949650, 17)\n",
      "‚úì Loaded processed products: (1000, 81)\n",
      "‚ö†Ô∏è Selected features file not found. Will use all features.\n",
      "\n",
      "Preprocessed data available: True\n",
      "Feature selection available: False\n",
      "‚úì Loaded processed adoption logs: (949650, 17)\n",
      "‚úì Loaded processed products: (1000, 81)\n",
      "‚ö†Ô∏è Selected features file not found. Will use all features.\n",
      "\n",
      "Preprocessed data available: True\n",
      "Feature selection available: False\n"
     ]
    }
   ],
   "source": [
    "# Load processed datasets from EDA\n",
    "print(\"üìä LOADING PROCESSED DATASETS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Try to load processed datasets first\n",
    "    adoption_data = pd.read_csv('data/processed_adoption_logs.csv')\n",
    "    print(f\"‚úì Loaded processed adoption logs: {adoption_data.shape}\")\n",
    "    \n",
    "    products_data = pd.read_csv('data/processed_products.csv')\n",
    "    print(f\"‚úì Loaded processed products: {products_data.shape}\")\n",
    "    \n",
    "    PROCESSED_DATA_AVAILABLE = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Processed datasets not found. Loading raw data...\")\n",
    "    PROCESSED_DATA_AVAILABLE = False\n",
    "    \n",
    "    # Load raw datasets\n",
    "    try:\n",
    "        adoption_data = pd.read_csv('data/data_adoption_logs.csv')\n",
    "        products_data = pd.read_csv('data/data_products.csv')\n",
    "        customers_data = pd.read_csv('data/data_customers.csv')\n",
    "        \n",
    "        print(f\"‚úì Loaded raw adoption logs: {adoption_data.shape}\")\n",
    "        print(f\"‚úì Loaded raw products: {products_data.shape}\")\n",
    "        print(f\"‚úì Loaded raw customers: {customers_data.shape}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error loading datasets: {e}\")\n",
    "        print(\"Please ensure data files are available in the data/ directory\")\n",
    "\n",
    "# Load feature selection if available\n",
    "try:\n",
    "    with open('selected_features.txt', 'r') as f:\n",
    "        selected_features = [line.strip() for line in f.readlines()]\n",
    "    print(f\"‚úì Loaded {len(selected_features)} selected features\")\n",
    "    FEATURE_SELECTION_AVAILABLE = True\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Selected features file not found. Will use all features.\")\n",
    "    FEATURE_SELECTION_AVAILABLE = False\n",
    "    selected_features = []\n",
    "\n",
    "print(f\"\\nPreprocessed data available: {PROCESSED_DATA_AVAILABLE}\")\n",
    "print(f\"Feature selection available: {FEATURE_SELECTION_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6a09fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß PREPARING MODELING DATASET\n",
      "========================================\n",
      "Using processed adoption logs as base dataset\n",
      "\n",
      "ModelingDataset prepared:\n",
      "  Features: 16\n",
      "  Samples: 949,650\n",
      "  Target distribution: {0: 711603, 1: 238047}\n",
      "  Positive rate: 0.2507\n"
     ]
    }
   ],
   "source": [
    "# Prepare modeling dataset\n",
    "print(\"\\nüîß PREPARING MODELING DATASET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if PROCESSED_DATA_AVAILABLE:\n",
    "    # Use processed data\n",
    "    modeling_data = adoption_data.copy()\n",
    "    print(\"Using processed adoption logs as base dataset\")\n",
    "    \n",
    "else:\n",
    "    # Quick preprocessing for raw data\n",
    "    print(\"Applying basic preprocessing to raw data...\")\n",
    "    \n",
    "    modeling_data = adoption_data.copy()\n",
    "    \n",
    "    # Basic encoding for categorical columns\n",
    "    categorical_cols = modeling_data.select_dtypes(include=['object']).columns.tolist()\n",
    "    categorical_cols = [col for col in categorical_cols if col not in ['user_id', 'product_id']]\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if modeling_data[col].nunique() <= 10:\n",
    "            # One-hot encode low cardinality\n",
    "            dummies = pd.get_dummies(modeling_data[col], prefix=col, drop_first=True)\n",
    "            modeling_data = pd.concat([modeling_data.drop(columns=[col]), dummies], axis=1)\n",
    "        else:\n",
    "            # Drop high cardinality categorical\n",
    "            modeling_data = modeling_data.drop(columns=[col])\n",
    "    \n",
    "    # Fill missing values\n",
    "    numeric_cols = modeling_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        if modeling_data[col].isnull().sum() > 0:\n",
    "            modeling_data[col].fillna(modeling_data[col].median(), inplace=True)\n",
    "\n",
    "# Prepare features and target\n",
    "if 'adopted' in modeling_data.columns:\n",
    "    target_col = 'adopted'\n",
    "    \n",
    "    # Remove ID columns from features\n",
    "    id_cols = ['user_id', 'product_id']\n",
    "    feature_cols = [col for col in modeling_data.columns if col not in [target_col] + id_cols]\n",
    "    \n",
    "    # Apply feature selection if available\n",
    "    if FEATURE_SELECTION_AVAILABLE and selected_features:\n",
    "        available_selected = [f for f in selected_features if f in feature_cols]\n",
    "        if available_selected:\n",
    "            feature_cols = available_selected\n",
    "            print(f\"Applied feature selection: {len(feature_cols)} features\")\n",
    "    \n",
    "    X = modeling_data[feature_cols]\n",
    "    y = modeling_data[target_col]\n",
    "    \n",
    "    # Convert boolean target to integer\n",
    "    if y.dtype == 'bool':\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    print(f\"\\nModelingDataset prepared:\")\n",
    "    print(f\"  Features: {X.shape[1]}\")\n",
    "    print(f\"  Samples: {X.shape[0]:,}\")\n",
    "    print(f\"  Target distribution: {y.value_counts().to_dict()}\")\n",
    "    print(f\"  Positive rate: {y.mean():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Target variable 'adopted' not found in dataset\")\n",
    "    X, y = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2f9b3",
   "metadata": {},
   "source": [
    "## 2. Data Splitting and Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2c0c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ IMPLEMENTING VALIDATION STRATEGY\n",
      "========================================\n",
      "Using tenure_days for time-based validation split\n",
      "Time-based split applied:\n",
      "  Train set: 759,720 samples\n",
      "  Test set: 189,930 samples\n",
      "  Train positive rate: 0.2507\n",
      "  Test positive rate: 0.2505\n",
      "Time-based split applied:\n",
      "  Train set: 759,720 samples\n",
      "  Test set: 189,930 samples\n",
      "  Train positive rate: 0.2507\n",
      "  Test positive rate: 0.2505\n",
      "\n",
      "Final data splits:\n",
      "  Training: 607,776 samples\n",
      "  Validation: 151,944 samples\n",
      "  Test: 189,930 samples\n",
      "\n",
      "üîç Checking data types before scaling...\n",
      "  Found non-numeric column: tenure_segment (dtype: object)\n",
      "    Sample values: ['New (0-30d)', 'Growing (91-365d)', 'Mature (1-3y)', 'Early (31-90d)', nan]\n",
      "  Found non-numeric column: recency_segment (dtype: object)\n",
      "    Sample values: ['Old (91-365d)', 'Recent (8-30d)', 'Moderate (31-90d)', 'Very Recent (0-7d)', nan]\n",
      "  Found non-numeric column: activity_segment (dtype: object)\n",
      "    Sample values: ['Low Activity', 'Medium Activity', 'High Activity', nan]\n",
      "  Found non-numeric column: monetary_segment (dtype: object)\n",
      "    Sample values: ['Low Spender', 'Medium Spender', 'High Spender']\n",
      "  Found non-numeric column: utilization_segment (dtype: object)\n",
      "    Sample values: ['Low Util (<30%)', 'Optimal Util (30-70%)', 'High Util (70-100%)', nan]\n",
      "\n",
      "‚ö†Ô∏è  Warning: 5 non-numeric columns found!\n",
      "Applying emergency categorical encoding...\n",
      "\n",
      "Final data splits:\n",
      "  Training: 607,776 samples\n",
      "  Validation: 151,944 samples\n",
      "  Test: 189,930 samples\n",
      "\n",
      "üîç Checking data types before scaling...\n",
      "  Found non-numeric column: tenure_segment (dtype: object)\n",
      "    Sample values: ['New (0-30d)', 'Growing (91-365d)', 'Mature (1-3y)', 'Early (31-90d)', nan]\n",
      "  Found non-numeric column: recency_segment (dtype: object)\n",
      "    Sample values: ['Old (91-365d)', 'Recent (8-30d)', 'Moderate (31-90d)', 'Very Recent (0-7d)', nan]\n",
      "  Found non-numeric column: activity_segment (dtype: object)\n",
      "    Sample values: ['Low Activity', 'Medium Activity', 'High Activity', nan]\n",
      "  Found non-numeric column: monetary_segment (dtype: object)\n",
      "    Sample values: ['Low Spender', 'Medium Spender', 'High Spender']\n",
      "  Found non-numeric column: utilization_segment (dtype: object)\n",
      "    Sample values: ['Low Util (<30%)', 'Optimal Util (30-70%)', 'High Util (70-100%)', nan]\n",
      "\n",
      "‚ö†Ô∏è  Warning: 5 non-numeric columns found!\n",
      "Applying emergency categorical encoding...\n",
      "  ‚úì Encoded tenure_segment: 6 unique values\n",
      "  ‚úì Encoded recency_segment: 5 unique values\n",
      "  ‚úì Encoded tenure_segment: 6 unique values\n",
      "  ‚úì Encoded recency_segment: 5 unique values\n",
      "  ‚úì Encoded activity_segment: 4 unique values\n",
      "  ‚úì Encoded monetary_segment: 3 unique values\n",
      "  ‚úì Encoded activity_segment: 4 unique values\n",
      "  ‚úì Encoded monetary_segment: 3 unique values\n",
      "  ‚úì Encoded utilization_segment: 4 unique values\n",
      "‚úì Emergency categorical encoding completed for 5 columns\n",
      "  ‚úì Encoded utilization_segment: 4 unique values\n",
      "‚úì Emergency categorical encoding completed for 5 columns\n",
      "‚úì Feature scaling applied\n",
      "‚úì Feature scaling applied\n"
     ]
    }
   ],
   "source": [
    "# Implement time-based data splitting for realistic evaluation\n",
    "print(\"üîÄ IMPLEMENTING VALIDATION STRATEGY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    # Check for temporal columns for time-based split\n",
    "    temporal_cols = [col for col in modeling_data.columns if 'date' in col.lower() or 'days' in col.lower()]\n",
    "    \n",
    "    if 'tenure_days' in modeling_data.columns:\n",
    "        # Use tenure_days for time-based split\n",
    "        print(\"Using tenure_days for time-based validation split\")\n",
    "        \n",
    "        # Sort by tenure to simulate temporal order\n",
    "        modeling_data_sorted = modeling_data.sort_values('tenure_days')\n",
    "        \n",
    "        # Use last 20% as test set (most recent interactions)\n",
    "        split_idx = int(0.8 * len(modeling_data_sorted))\n",
    "        \n",
    "        train_data = modeling_data_sorted.iloc[:split_idx]\n",
    "        test_data = modeling_data_sorted.iloc[split_idx:]\n",
    "        \n",
    "        X_train = train_data[feature_cols]\n",
    "        y_train = train_data[target_col].astype(int)\n",
    "        X_test = test_data[feature_cols]\n",
    "        y_test = test_data[target_col].astype(int)\n",
    "        \n",
    "        print(f\"Time-based split applied:\")\n",
    "        print(f\"  Train set: {X_train.shape[0]:,} samples\")\n",
    "        print(f\"  Test set: {X_test.shape[0]:,} samples\")\n",
    "        print(f\"  Train positive rate: {y_train.mean():.4f}\")\n",
    "        print(f\"  Test positive rate: {y_test.mean():.4f}\")\n",
    "        \n",
    "    else:\n",
    "        # Standard stratified split\n",
    "        print(\"Using stratified random split\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Stratified split applied:\")\n",
    "        print(f\"  Train set: {X_train.shape[0]:,} samples\")\n",
    "        print(f\"  Test set: {X_test.shape[0]:,} samples\")\n",
    "        print(f\"  Train positive rate: {y_train.mean():.4f}\")\n",
    "        print(f\"  Test positive rate: {y_test.mean():.4f}\")\n",
    "    \n",
    "    # Create validation set from training data\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFinal data splits:\")\n",
    "    print(f\"  Training: {X_train_final.shape[0]:,} samples\")\n",
    "    print(f\"  Validation: {X_val.shape[0]:,} samples\")\n",
    "    print(f\"  Test: {X_test.shape[0]:,} samples\")\n",
    "    \n",
    "    # Check for non-numeric columns before scaling\n",
    "    print(\"\\nüîç Checking data types before scaling...\")\n",
    "    non_numeric_cols = []\n",
    "    for col in X_train_final.columns:\n",
    "        if X_train_final[col].dtype == 'object' or X_train_final[col].dtype.name == 'category':\n",
    "            non_numeric_cols.append(col)\n",
    "            print(f\"  Found non-numeric column: {col} (dtype: {X_train_final[col].dtype})\")\n",
    "            # Show sample values\n",
    "            print(f\"    Sample values: {X_train_final[col].unique()[:5].tolist()}\")\n",
    "    \n",
    "    if non_numeric_cols:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: {len(non_numeric_cols)} non-numeric columns found!\")\n",
    "        print(\"Applying emergency categorical encoding...\")\n",
    "        \n",
    "        # Emergency encoding for remaining categorical columns\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        label_encoders = {}\n",
    "        \n",
    "        for col in non_numeric_cols:\n",
    "            le = LabelEncoder()\n",
    "            # Fit on all data (train + val + test) to ensure consistent encoding\n",
    "            all_values = pd.concat([\n",
    "                X_train_final[col], X_val[col], X_test[col]\n",
    "            ]).astype(str)\n",
    "            le.fit(all_values)\n",
    "            \n",
    "            # Transform each set\n",
    "            X_train_final[col] = le.transform(X_train_final[col].astype(str))\n",
    "            X_val[col] = le.transform(X_val[col].astype(str))\n",
    "            X_test[col] = le.transform(X_test[col].astype(str))\n",
    "            \n",
    "            label_encoders[col] = le\n",
    "            print(f\"  ‚úì Encoded {col}: {len(le.classes_)} unique values\")\n",
    "        \n",
    "        print(f\"‚úì Emergency categorical encoding completed for {len(non_numeric_cols)} columns\")\n",
    "    \n",
    "    # Now scale features (all should be numeric)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"‚úì Feature scaling applied\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed with modeling - data preparation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e292d9",
   "metadata": {},
   "source": [
    "## 3. Baseline Models Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1220febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ TRAINING BASELINE MODELS\n",
      "========================================\n",
      "\n",
      "1Ô∏è‚É£ Training Logistic Regression...\n",
      "   ‚úì Logistic Regression trained\n",
      "\n",
      "2Ô∏è‚É£ Training Random Forest...\n",
      "   ‚úì Logistic Regression trained\n",
      "\n",
      "2Ô∏è‚É£ Training Random Forest...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.64 MiB for an array with shape (607776,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\_utils.py\", line 72, in __call__\n    return self.func(**kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n    tree._fit(\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 305, in _fit\n    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 286, in unique\n    ret = _unique1d(ar, return_index, return_inverse, return_counts,\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_arraysetops_impl.py\", line 375, in _unique1d\n    imask = np.cumsum(mask) - 1\n            ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py\", line 2955, in cumsum\n    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\ctv.kietpt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py\", line 57, in _wrapfunc\n    return bound(*args, **kwds)\n           ^^^^^^^^^^^^^^^^^^^^\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 4.64 MiB for an array with shape (607776,) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2Ô∏è‚É£ Training Random Forest...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m models[\u001b[33m'\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m'\u001b[39m] = RandomForestClassifier(\n\u001b[32m     23\u001b[39m     n_estimators=\u001b[32m100\u001b[39m,\n\u001b[32m     24\u001b[39m     random_state=RANDOM_STATE,\n\u001b[32m     25\u001b[39m     class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     26\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrandom_forest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   ‚úì Random Forest trained\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 3. XGBoost (if available)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 4.64 MiB for an array with shape (607776,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Define and train baseline models\n",
    "print(\"ü§ñ TRAINING BASELINE MODELS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    # Initialize models\n",
    "    models = {}\n",
    "    model_results = {}\n",
    "    \n",
    "    # 1. Logistic Regression\n",
    "    print(\"\\n1Ô∏è‚É£ Training Logistic Regression...\")\n",
    "    models['logistic'] = LogisticRegression(\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000\n",
    "    )\n",
    "    models['logistic'].fit(X_train_scaled, y_train_final)\n",
    "    print(\"   ‚úì Logistic Regression trained\")\n",
    "    \n",
    "    # 2. Random Forest\n",
    "    print(\"\\n2Ô∏è‚É£ Training Random Forest...\")\n",
    "    models['random_forest'] = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['random_forest'].fit(X_train_final, y_train_final)\n",
    "    print(\"   ‚úì Random Forest trained\")\n",
    "    \n",
    "    # 3. XGBoost (if available)\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        print(\"\\n3Ô∏è‚É£ Training XGBoost...\")\n",
    "        \n",
    "        # Calculate scale_pos_weight for class imbalance\n",
    "        scale_pos_weight = (y_train_final == 0).sum() / (y_train_final == 1).sum()\n",
    "        \n",
    "        models['xgboost'] = xgb.XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "        models['xgboost'].fit(X_train_final, y_train_final)\n",
    "        print(\"   ‚úì XGBoost trained\")\n",
    "    \n",
    "    # 4. Naive Bayes\n",
    "    print(\"\\n4Ô∏è‚É£ Training Naive Bayes...\")\n",
    "    models['naive_bayes'] = GaussianNB()\n",
    "    models['naive_bayes'].fit(X_train_scaled, y_train_final)\n",
    "    print(\"   ‚úì Naive Bayes trained\")\n",
    "    \n",
    "    # 5. Neural Network\n",
    "    print(\"\\n5Ô∏è‚É£ Training Neural Network...\")\n",
    "    models['neural_network'] = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    models['neural_network'].fit(X_train_scaled, y_train_final)\n",
    "    print(\"   ‚úì Neural Network trained\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Trained {len(models)} baseline models\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot train models - data not available\")\n",
    "    models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf954856",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff401ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COMPREHENSIVE MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "üîç Evaluating LOGISTIC...\n",
      "   Validation - Precision: 0.2501, Recall: 0.4795, F1: 0.3287\n",
      "   Test - Precision: 0.2513, Recall: 0.2233, F1: 0.2365\n",
      "\n",
      "üîç Evaluating RANDOM_FOREST...\n",
      "   Validation - Precision: 0.2501, Recall: 0.4795, F1: 0.3287\n",
      "   Test - Precision: 0.2513, Recall: 0.2233, F1: 0.2365\n",
      "\n",
      "üîç Evaluating RANDOM_FOREST...\n",
      "   Validation - Precision: 0.2381, Recall: 0.0003, F1: 0.0005\n",
      "   Test - Precision: 0.3161, Recall: 0.0010, F1: 0.0021\n",
      "\n",
      "üîç Evaluating NAIVE_BAYES...\n",
      "   Validation - Precision: 0.2381, Recall: 0.0003, F1: 0.0005\n",
      "   Test - Precision: 0.3161, Recall: 0.0010, F1: 0.0021\n",
      "\n",
      "üîç Evaluating NAIVE_BAYES...\n",
      "   Validation - Precision: 0.2143, Recall: 0.0001, F1: 0.0002\n",
      "   Test - Precision: 0.2500, Recall: 0.0001, F1: 0.0003\n",
      "\n",
      "üîç Evaluating NEURAL_NETWORK...\n",
      "   Validation - Precision: 0.2143, Recall: 0.0001, F1: 0.0002\n",
      "   Test - Precision: 0.2500, Recall: 0.0001, F1: 0.0003\n",
      "\n",
      "üîç Evaluating NEURAL_NETWORK...\n",
      "   Validation - Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "   Test - Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "‚úÖ Model evaluation completed\n",
      "   Validation - Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "   Test - Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "‚úÖ Model evaluation completed\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive model evaluation\n",
    "print(\"üìä COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if models and X is not None:\n",
    "    evaluation_results = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nüîç Evaluating {model_name.upper()}...\")\n",
    "        \n",
    "        # Use scaled features for models that need them\n",
    "        if model_name in ['logistic', 'naive_bayes', 'neural_network']:\n",
    "            val_features = X_val_scaled\n",
    "            test_features = X_test_scaled\n",
    "        else:\n",
    "            val_features = X_val\n",
    "            test_features = X_test\n",
    "        \n",
    "        # Validation predictions\n",
    "        y_val_pred = model.predict(val_features)\n",
    "        y_val_proba = model.predict_proba(val_features)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Test predictions\n",
    "        y_test_pred = model.predict(test_features)\n",
    "        y_test_proba = model.predict_proba(test_features)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Store predictions\n",
    "        predictions[model_name] = {\n",
    "            'val_pred': y_val_pred,\n",
    "            'val_proba': y_val_proba,\n",
    "            'test_pred': y_test_pred,\n",
    "            'test_proba': y_test_proba\n",
    "        }\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_metrics = {\n",
    "            'precision': precision_score(y_val, y_val_pred),\n",
    "            'recall': recall_score(y_val, y_val_pred),\n",
    "            'f1': f1_score(y_val, y_val_pred),\n",
    "            'roc_auc': roc_auc_score(y_val, y_val_proba) if y_val_proba is not None else None\n",
    "        }\n",
    "        \n",
    "        test_metrics = {\n",
    "            'precision': precision_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred),\n",
    "            'f1': f1_score(y_test, y_test_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_test_proba) if y_test_proba is not None else None\n",
    "        }\n",
    "        \n",
    "        evaluation_results[model_name] = {\n",
    "            'validation': val_metrics,\n",
    "            'test': test_metrics\n",
    "        }\n",
    "        \n",
    "        print(f\"   Validation - Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "        print(f\"   Test - Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}, F1: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Model evaluation completed\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot evaluate models - models not trained\")\n",
    "    evaluation_results = {}\n",
    "    predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c61210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà MODEL PERFORMANCE COMPARISON\n",
      "==================================================\n",
      "\n",
      "üìä Detailed Results:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('f1', 'test')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('f1', 'validation')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('precision', 'test')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('precision', 'validation')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('recall', 'test')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('recall', 'validation')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('roc_auc', 'test')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('roc_auc', 'validation')",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "776f0a2d-997f-4720-992a-47d8f6f79f45",
       "rows": [
        [
         "logistic",
         "0.2365",
         "0.3287",
         "0.2513",
         "0.2501",
         "0.2233",
         "0.4795",
         "0.5018",
         "0.5006"
        ],
        [
         "naive_bayes",
         "0.0003",
         "0.0002",
         "0.25",
         "0.2143",
         "0.0001",
         "0.0001",
         "0.5024",
         "0.5008"
        ],
        [
         "neural_network",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.5022",
         "0.4966"
        ],
        [
         "random_forest",
         "0.0021",
         "0.0005",
         "0.3161",
         "0.2381",
         "0.001",
         "0.0003",
         "0.4994",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th>test</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.3287</td>\n",
       "      <td>0.2513</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.5006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.5008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_network</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.4966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f1            precision             recall             \\\n",
       "Split             test validation      test validation    test validation   \n",
       "Model                                                                       \n",
       "logistic        0.2365     0.3287    0.2513     0.2501  0.2233     0.4795   \n",
       "naive_bayes     0.0003     0.0002    0.2500     0.2143  0.0001     0.0001   \n",
       "neural_network  0.0000     0.0000    0.0000     0.0000  0.0000     0.0000   \n",
       "random_forest   0.0021     0.0005    0.3161     0.2381  0.0010     0.0003   \n",
       "\n",
       "               roc_auc             \n",
       "Split             test validation  \n",
       "Model                              \n",
       "logistic        0.5018     0.5006  \n",
       "naive_bayes     0.5024     0.5008  \n",
       "neural_network  0.5022     0.4966  \n",
       "random_forest   0.4994     0.5000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best Model: LOGISTIC (Test F1: 0.2365)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Precision",
         "type": "bar",
         "x": [
          "logistic",
          "random_forest",
          "naive_bayes",
          "neural_network"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "JJu4L6IU0D87VLdDdTvUPwAAAAAAANA/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "name": "Recall",
         "type": "bar",
         "x": [
          "logistic",
          "random_forest",
          "naive_bayes",
          "neural_network"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "5qUbJZiVzD/hqByLBuBQP46/K53chyA/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        },
        {
         "name": "F1-Score",
         "type": "bar",
         "x": [
          "logistic",
          "random_forest",
          "naive_bayes",
          "neural_network"
         ],
         "xaxis": "x3",
         "y": {
          "bdata": "fTZL4HhEzj/lPJcL/9FgP7qEW1y6hTA/AAAAAAAAAAA=",
          "dtype": "f8"
         },
         "yaxis": "y3"
        },
        {
         "name": "ROC-AUC",
         "type": "bar",
         "x": [
          "logistic",
          "random_forest",
          "naive_bayes",
          "neural_network"
         ],
         "xaxis": "x4",
         "y": {
          "bdata": "FDJibNUO4D8eTVBAuvbfP1KewhCIE+A/ozfj1L0R4D8=",
          "dtype": "f8"
         },
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Precision Comparison",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Recall Comparison",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1-Score Comparison",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ROC-AUC Comparison",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Performance Comparison (Test Set)"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create comprehensive results comparison\n",
    "if evaluation_results:\n",
    "    print(\"\\nüìà MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_data = []\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        for split, metrics in results.items():\n",
    "            row = {'Model': model_name, 'Split': split}\n",
    "            row.update(metrics)\n",
    "            results_data.append(row)\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Display results table\n",
    "    print(\"\\nüìä Detailed Results:\")\n",
    "    pivot_results = results_df.pivot_table(\n",
    "        index='Model', \n",
    "        columns='Split', \n",
    "        values=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "        aggfunc='first'\n",
    "    ).round(4)\n",
    "    \n",
    "    display(pivot_results)\n",
    "    \n",
    "    # Identify best model\n",
    "    test_f1_scores = results_df[results_df['Split'] == 'test']['f1']\n",
    "    best_model_idx = test_f1_scores.idxmax()\n",
    "    best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "    best_f1 = results_df.loc[best_model_idx, 'f1']\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Model: {best_model_name.upper()} (Test F1: {best_f1:.4f})\")\n",
    "    \n",
    "    # Visualize results\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Precision Comparison', 'Recall Comparison', 'F1-Score Comparison', 'ROC-AUC Comparison')\n",
    "    )\n",
    "    \n",
    "    test_results = results_df[results_df['Split'] == 'test']\n",
    "    \n",
    "    # Precision\n",
    "    fig.add_trace(go.Bar(x=test_results['Model'], y=test_results['precision'], name='Precision'), row=1, col=1)\n",
    "    \n",
    "    # Recall\n",
    "    fig.add_trace(go.Bar(x=test_results['Model'], y=test_results['recall'], name='Recall'), row=1, col=2)\n",
    "    \n",
    "    # F1-Score\n",
    "    fig.add_trace(go.Bar(x=test_results['Model'], y=test_results['f1'], name='F1-Score'), row=2, col=1)\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc_auc_data = test_results.dropna(subset=['roc_auc'])\n",
    "    fig.add_trace(go.Bar(x=roc_auc_data['Model'], y=roc_auc_data['roc_auc'], name='ROC-AUC'), row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(height=800, title_text=\"Model Performance Comparison (Test Set)\", showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d99ef6",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç FEATURE IMPORTANCE ANALYSIS\n",
      "========================================\n",
      "\n",
      "üå≤ Random Forest - Top 10 Important Features:\n",
      "   monetary_volume: 0.1434\n",
      "   reward_redemption_rate: 0.1379\n",
      "   utilisation_ratio: 0.1348\n",
      "   recency_days: 0.1287\n",
      "   tenure_months: 0.0821\n",
      "   tenure_years: 0.0818\n",
      "   tenure_days: 0.0818\n",
      "   product_id_frequency: 0.0645\n",
      "   activity_intensity: 0.0627\n",
      "   user_id_frequency: 0.0285\n",
      "\n",
      "üìà Logistic Regression - Top 10 Important Features (by |coefficient|):\n",
      "   recency_days: -0.0046\n",
      "   utilisation_ratio: 0.0039\n",
      "   monetary_volume: -0.0038\n",
      "   reward_redemption_rate: -0.0034\n",
      "   tenure_segment: -0.0034\n",
      "   recency_segment: 0.0033\n",
      "   activity_intensity: 0.0032\n",
      "   activity_segment: -0.0029\n",
      "   user_id_frequency: -0.0019\n",
      "   monetary_segment: -0.0016\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Feature importance analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if models and X is not None:\n",
    "    feature_importance_results = {}\n",
    "    \n",
    "    # Random Forest Feature Importance\n",
    "    if 'random_forest' in models:\n",
    "        rf_importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': models['random_forest'].feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        feature_importance_results['random_forest'] = rf_importance\n",
    "        \n",
    "        print(\"\\nüå≤ Random Forest - Top 10 Important Features:\")\n",
    "        for i, row in rf_importance.head(10).iterrows():\n",
    "            print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # XGBoost Feature Importance\n",
    "    if 'xgboost' in models and XGBOOST_AVAILABLE:\n",
    "        xgb_importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': models['xgboost'].feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        feature_importance_results['xgboost'] = xgb_importance\n",
    "        \n",
    "        print(\"\\n‚ö° XGBoost - Top 10 Important Features:\")\n",
    "        for i, row in xgb_importance.head(10).iterrows():\n",
    "            print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Logistic Regression Coefficients\n",
    "    if 'logistic' in models:\n",
    "        lr_coefs = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'coefficient': models['logistic'].coef_[0]\n",
    "        })\n",
    "        lr_coefs['abs_coefficient'] = lr_coefs['coefficient'].abs()\n",
    "        lr_coefs = lr_coefs.sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        feature_importance_results['logistic'] = lr_coefs\n",
    "        \n",
    "        print(\"\\nüìà Logistic Regression - Top 10 Important Features (by |coefficient|):\")\n",
    "        for i, row in lr_coefs.head(10).iterrows():\n",
    "            print(f\"   {row['feature']}: {row['coefficient']:.4f}\")\n",
    "    \n",
    "    # Visualize feature importance (Random Forest)\n",
    "    if 'random_forest' in feature_importance_results:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top_features = feature_importance_results['random_forest'].head(15)\n",
    "        sns.barplot(data=top_features, x='importance', y='feature')\n",
    "        plt.title('Top 15 Feature Importances (Random Forest)')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Feature importance analysis completed\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot analyze feature importance - models not available\")\n",
    "    feature_importance_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11552e",
   "metadata": {},
   "source": [
    "## 6. Model Interpretation and Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e94b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíº BUSINESS INSIGHTS AND MODEL INTERPRETATION\n",
      "============================================================\n",
      "\n",
      "üìä Performance Insights:\n",
      "   ‚Ä¢ Best performing model: logistic\n",
      "   ‚Ä¢ Precision: 0.2513 (25.1% of predicted adoptions are correct)\n",
      "   ‚Ä¢ Recall: 0.2233 (22.3% of actual adoptions are captured)\n",
      "   ‚Ä¢ F1-Score: 0.2365 (balanced precision-recall performance)\n",
      "\n",
      "üéØ Key Predictive Features:\n",
      "   ‚Ä¢ monetary_volume: 0.1434 importance\n",
      "     ‚Üí Customer spending behavior is a strong predictor\n",
      "   ‚Ä¢ reward_redemption_rate: 0.1379 importance\n",
      "     ‚Üí Significant predictor of adoption behavior\n",
      "   ‚Ä¢ utilisation_ratio: 0.1348 importance\n",
      "     ‚Üí Significant predictor of adoption behavior\n",
      "   ‚Ä¢ recency_days: 0.1287 importance\n",
      "     ‚Üí Significant predictor of adoption behavior\n",
      "   ‚Ä¢ tenure_months: 0.0821 importance\n",
      "     ‚Üí Customer relationship length affects adoption likelihood\n",
      "\n",
      "üí∞ Estimated Business Impact:\n",
      "   ‚Ä¢ Total customers evaluated: 189,930\n",
      "   ‚Ä¢ Actual adoptions: 47,574\n",
      "   ‚Ä¢ Model predictions: 42,283\n",
      "   ‚Ä¢ Correctly identified adoptions: 10,624\n",
      "   ‚Ä¢ Targeting efficiency: 25.13%\n",
      "   ‚Ä¢ Estimated cost savings: $1,476,470 (vs. targeting all customers)\n",
      "\n",
      "üéØ Strategic Recommendations:\n",
      "   1. Deploy logistic model for customer targeting\n",
      "   2. Focus marketing on high-importance feature segments\n",
      "   3. Implement A/B testing to validate model performance\n",
      "   4. Monitor model performance for drift over time\n",
      "   5. Collect additional data on top predictive features\n",
      "\n",
      "üìÅ Business insights saved to 'baseline_modeling_insights.json'\n"
     ]
    }
   ],
   "source": [
    "# Business-focused model interpretation\n",
    "print(\"üíº BUSINESS INSIGHTS AND MODEL INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if evaluation_results and feature_importance_results:\n",
    "    business_insights = []\n",
    "    \n",
    "    # Performance insights\n",
    "    print(\"\\nüìä Performance Insights:\")\n",
    "    \n",
    "    best_model_name = best_model_name if 'best_model_name' in locals() else list(models.keys())[0]\n",
    "    best_model_results = evaluation_results[best_model_name]['test']\n",
    "    \n",
    "    precision = best_model_results['precision']\n",
    "    recall = best_model_results['recall']\n",
    "    f1 = best_model_results['f1']\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Best performing model: {best_model_name}\")\n",
    "    print(f\"   ‚Ä¢ Precision: {precision:.4f} ({precision*100:.1f}% of predicted adoptions are correct)\")\n",
    "    print(f\"   ‚Ä¢ Recall: {recall:.4f} ({recall*100:.1f}% of actual adoptions are captured)\")\n",
    "    print(f\"   ‚Ä¢ F1-Score: {f1:.4f} (balanced precision-recall performance)\")\n",
    "    \n",
    "    business_insights.append(f\"Best model achieves {precision*100:.1f}% precision and {recall*100:.1f}% recall\")\n",
    "    \n",
    "    # Feature insights\n",
    "    if 'random_forest' in feature_importance_results:\n",
    "        print(\"\\nüéØ Key Predictive Features:\")\n",
    "        top_features = feature_importance_results['random_forest'].head(5)\n",
    "        \n",
    "        for i, row in top_features.iterrows():\n",
    "            feature_name = row['feature']\n",
    "            importance = row['importance']\n",
    "            print(f\"   ‚Ä¢ {feature_name}: {importance:.4f} importance\")\n",
    "            \n",
    "            # Interpret feature meaning\n",
    "            if 'monetary' in feature_name.lower():\n",
    "                interpretation = \"Customer spending behavior is a strong predictor\"\n",
    "            elif 'activity' in feature_name.lower():\n",
    "                interpretation = \"Customer engagement level drives adoption\"\n",
    "            elif 'tenure' in feature_name.lower():\n",
    "                interpretation = \"Customer relationship length affects adoption likelihood\"\n",
    "            elif 'risk' in feature_name.lower():\n",
    "                interpretation = \"Risk profile influences product adoption decisions\"\n",
    "            else:\n",
    "                interpretation = \"Significant predictor of adoption behavior\"\n",
    "            \n",
    "            print(f\"     ‚Üí {interpretation}\")\n",
    "            business_insights.append(f\"{feature_name} is a key predictor: {interpretation}\")\n",
    "    \n",
    "    # Business impact estimation\n",
    "    print(\"\\nüí∞ Estimated Business Impact:\")\n",
    "    \n",
    "    if 'y_test' in locals():\n",
    "        total_customers = len(y_test)\n",
    "        actual_adoptions = y_test.sum()\n",
    "        \n",
    "        # Calculate potential impact with best model\n",
    "        if best_model_name in predictions:\n",
    "            predicted_adoptions = predictions[best_model_name]['test_pred'].sum()\n",
    "            true_positives = ((predictions[best_model_name]['test_pred'] == 1) & (y_test == 1)).sum()\n",
    "            \n",
    "            print(f\"   ‚Ä¢ Total customers evaluated: {total_customers:,}\")\n",
    "            print(f\"   ‚Ä¢ Actual adoptions: {actual_adoptions:,}\")\n",
    "            print(f\"   ‚Ä¢ Model predictions: {predicted_adoptions:,}\")\n",
    "            print(f\"   ‚Ä¢ Correctly identified adoptions: {true_positives:,}\")\n",
    "            \n",
    "            # Estimate targeting efficiency\n",
    "            if predicted_adoptions > 0:\n",
    "                targeting_efficiency = true_positives / predicted_adoptions\n",
    "                print(f\"   ‚Ä¢ Targeting efficiency: {targeting_efficiency:.2%}\")\n",
    "                \n",
    "                # Estimate cost savings (assuming targeting costs)\n",
    "                cost_per_target = 10  # Example cost per customer targeted\n",
    "                baseline_cost = total_customers * cost_per_target\n",
    "                optimized_cost = predicted_adoptions * cost_per_target\n",
    "                cost_savings = baseline_cost - optimized_cost\n",
    "                \n",
    "                print(f\"   ‚Ä¢ Estimated cost savings: ${cost_savings:,.0f} (vs. targeting all customers)\")\n",
    "                business_insights.append(f\"Model-based targeting could save ${cost_savings:,.0f} in marketing costs\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\nüéØ Strategic Recommendations:\")\n",
    "    recommendations = [\n",
    "        f\"Deploy {best_model_name} model for customer targeting\",\n",
    "        \"Focus marketing on high-importance feature segments\",\n",
    "        \"Implement A/B testing to validate model performance\",\n",
    "        \"Monitor model performance for drift over time\",\n",
    "        \"Collect additional data on top predictive features\"\n",
    "    ]\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"   {i}. {rec}\")\n",
    "    \n",
    "    # Store insights\n",
    "    business_summary = {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'best_model': best_model_name,\n",
    "        'performance_metrics': best_model_results,\n",
    "        'key_insights': business_insights,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "    \n",
    "    with open('baseline_modeling_insights.json', 'w') as f:\n",
    "        json.dump(business_summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"\\nüìÅ Business insights saved to 'baseline_modeling_insights.json'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot generate business insights - evaluation results not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a13d46",
   "metadata": {},
   "source": [
    "## 7. Model Persistence and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b6850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ MODEL PERSISTENCE AND DEPLOYMENT PREPARATION\n",
      "============================================================\n",
      "üìÅ Model directory: model\n",
      "‚úÖ Best model (logistic) saved to 'model\\best_model_logistic.joblib'\n",
      "\n",
      "üíæ Saving individual models...\n",
      "  ‚úÖ logistic model saved to 'model\\model_logistic.joblib'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ random_forest model saved to 'model\\model_random_forest.joblib'\n",
      "  ‚úÖ naive_bayes model saved to 'model\\model_naive_bayes.joblib'\n",
      "  ‚úÖ neural_network model saved to 'model\\model_neural_network.joblib'\n",
      "‚úÖ Evaluation results saved to 'model\\evaluation_results.json'\n",
      "‚úÖ Feature importance saved to 'model\\feature_importance.json'\n",
      "‚úÖ Model metadata saved to 'model\\model_metadata.json'\n",
      "\n",
      "üìã MODEL INVENTORY:\n",
      "  üìÅ Model Directory: model\n",
      "  üèÜ Best Model: logistic (F1: 0.2365)\n",
      "  üìä Models Saved: 4\n",
      "  üíæ Total Files: 7 (models + metadata + evaluation + feature_importance)\n",
      "\n",
      "‚ú® MEMORY OPTIMIZATION:\n",
      "  ‚úÖ Models saved individually to prevent MemoryError\n",
      "  ‚úÖ Using joblib for efficient serialization\n",
      "  ‚úÖ Metadata stored separately for easy access\n",
      "\n",
      "üéØ NEXT STEPS FOR ADVANCED MODELING:\n",
      "========================================\n",
      "1. Advanced Feature Engineering\n",
      "   - Create interaction features between customer and product attributes\n",
      "   - Implement temporal features and seasonality patterns\n",
      "   - Develop customer lifetime value predictions\n",
      "\n",
      "2. Model Optimization\n",
      "   - Hyperparameter tuning with GridSearch/RandomSearch\n",
      "   - Ensemble methods (Voting, Stacking, Blending)\n",
      "   - Advanced algorithms (LightGBM, CatBoost)\n",
      "\n",
      "3. Evaluation Enhancement\n",
      "   - Business-specific metrics (Revenue lift, Customer acquisition cost)\n",
      "   - Time-series validation for temporal robustness\n",
      "   - Fairness and bias analysis\n",
      "\n",
      "4. Production Deployment\n",
      "   - Model serving infrastructure\n",
      "   - A/B testing framework\n",
      "   - Monitoring and alerting system\n",
      "   - Automated retraining pipeline\n",
      "\n",
      "üöÄ Ready to proceed with advanced modeling techniques!\n",
      "üìä Baseline established - all models trained and evaluated\n",
      "‚úÖ Foundation prepared for production deployment\n"
     ]
    }
   ],
   "source": [
    "# Save models and prepare for next steps\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üíæ MODEL PERSISTENCE AND DEPLOYMENT PREPARATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "model_dir = 'model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(f\"üìÅ Model directory: {model_dir}\")\n",
    "\n",
    "if models:\n",
    "    # Save best model with comprehensive package\n",
    "    best_model = models[best_model_name]\n",
    "    \n",
    "    # Create model package for best model\n",
    "    best_model_package = {\n",
    "        'model': best_model,\n",
    "        'scaler': scaler if best_model_name in ['logistic', 'naive_bayes', 'neural_network'] else None,\n",
    "        'feature_columns': feature_cols,\n",
    "        'model_type': best_model_name,\n",
    "        'performance_metrics': evaluation_results[best_model_name]['test'],\n",
    "        'training_date': datetime.now().isoformat(),\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X),\n",
    "            'features': len(feature_cols),\n",
    "            'positive_rate': float(y.mean())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save best model using joblib (more memory efficient)\n",
    "    best_model_path = os.path.join(model_dir, f'best_model_{best_model_name}.joblib')\n",
    "    joblib.dump(best_model_package, best_model_path)\n",
    "    print(f\"‚úÖ Best model ({best_model_name}) saved to '{best_model_path}'\")\n",
    "    \n",
    "    # Save individual models to avoid memory issues\n",
    "    print(\"\\nüíæ Saving individual models...\")\n",
    "    saved_models = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Create individual model package\n",
    "            individual_package = {\n",
    "                'model': model,\n",
    "                'scaler': scaler if model_name in ['logistic', 'naive_bayes', 'neural_network'] else None,\n",
    "                'feature_columns': feature_cols,\n",
    "                'model_type': model_name,\n",
    "                'performance_metrics': evaluation_results[model_name]['test'] if model_name in evaluation_results else None,\n",
    "                'training_date': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Save individual model\n",
    "            model_path = os.path.join(model_dir, f'model_{model_name}.joblib')\n",
    "            joblib.dump(individual_package, model_path)\n",
    "            saved_models[model_name] = model_path\n",
    "            print(f\"  ‚úÖ {model_name} model saved to '{model_path}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Failed to save {model_name}: {str(e)}\")\n",
    "    \n",
    "    # Save model metadata and evaluation results separately\n",
    "    model_metadata = {\n",
    "        'baseline_modeling_complete': True,\n",
    "        'models_trained': list(models.keys()),\n",
    "        'saved_models': saved_models,\n",
    "        'best_model': best_model_name,\n",
    "        'best_model_path': best_model_path,\n",
    "        'best_model_metrics': evaluation_results[best_model_name]['test'],\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X),\n",
    "            'features': len(feature_cols),\n",
    "            'positive_rate': float(y.mean()),\n",
    "            'feature_columns': feature_cols\n",
    "        },\n",
    "        'training_timestamp': datetime.now().isoformat(),\n",
    "        'next_steps': [\n",
    "            \"Implement advanced feature engineering\",\n",
    "            \"Experiment with ensemble methods\",\n",
    "            \"Optimize hyperparameters using GridSearch/RandomSearch\",\n",
    "            \"Deploy best model for A/B testing\",\n",
    "            \"Set up monitoring and retraining pipeline\",\n",
    "            \"Implement model explainability (SHAP, LIME)\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save evaluation results separately\n",
    "    evaluation_path = os.path.join(model_dir, 'evaluation_results.json')\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "        json.dump(evaluation_results, f, indent=2, default=str)\n",
    "    print(f\"‚úÖ Evaluation results saved to '{evaluation_path}'\")\n",
    "    \n",
    "    # Save feature importance separately\n",
    "    if feature_importance_results:\n",
    "        feature_importance_path = os.path.join(model_dir, 'feature_importance.json')\n",
    "        with open(feature_importance_path, 'w') as f:\n",
    "            json.dump(feature_importance_results, f, indent=2, default=str)\n",
    "        print(f\"‚úÖ Feature importance saved to '{feature_importance_path}'\")\n",
    "    \n",
    "    # Save model metadata\n",
    "    metadata_path = os.path.join(model_dir, 'model_metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(model_metadata, f, indent=2, default=str)\n",
    "    print(f\"‚úÖ Model metadata saved to '{metadata_path}'\")\n",
    "    \n",
    "    # Create model inventory\n",
    "    print(f\"\\nüìã MODEL INVENTORY:\")\n",
    "    print(f\"  üìÅ Model Directory: {model_dir}\")\n",
    "    # Safe access to metrics\n",
    "    if best_model_name in evaluation_results:\n",
    "        best_metrics = evaluation_results[best_model_name]['test']\n",
    "        f1_score_val = best_metrics.get('f1', best_metrics.get('f1_score', 'N/A'))\n",
    "        print(f\"  üèÜ Best Model: {best_model_name} (F1: {f1_score_val:.4f})\")\n",
    "    else:\n",
    "        print(f\"  üèÜ Best Model: {best_model_name}\")\n",
    "    print(f\"  üìä Models Saved: {len(saved_models)}\")\n",
    "    print(f\"  üíæ Total Files: {len(saved_models) + 3} (models + metadata + evaluation + feature_importance)\")\n",
    "    \n",
    "    # Memory usage optimization message\n",
    "    print(f\"\\n‚ú® MEMORY OPTIMIZATION:\")\n",
    "    print(f\"  ‚úÖ Models saved individually to prevent MemoryError\")\n",
    "    print(f\"  ‚úÖ Using joblib for efficient serialization\")\n",
    "    print(f\"  ‚úÖ Metadata stored separately for easy access\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No models available to save\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS FOR ADVANCED MODELING:\")\n",
    "print(\"=\" * 40)\n",
    "next_steps = [\n",
    "    \"1. Advanced Feature Engineering\",\n",
    "    \"   - Create interaction features between customer and product attributes\",\n",
    "    \"   - Implement temporal features and seasonality patterns\",\n",
    "    \"   - Develop customer lifetime value predictions\",\n",
    "    \"\",\n",
    "    \"2. Model Optimization\",\n",
    "    \"   - Hyperparameter tuning with GridSearch/RandomSearch\",\n",
    "    \"   - Ensemble methods (Voting, Stacking, Blending)\",\n",
    "    \"   - Advanced algorithms (LightGBM, CatBoost)\",\n",
    "    \"\",\n",
    "    \"3. Evaluation Enhancement\", \n",
    "    \"   - Business-specific metrics (Revenue lift, Customer acquisition cost)\",\n",
    "    \"   - Time-series validation for temporal robustness\",\n",
    "    \"   - Fairness and bias analysis\",\n",
    "    \"\",\n",
    "    \"4. Production Deployment\",\n",
    "    \"   - Model serving infrastructure\",\n",
    "    \"   - A/B testing framework\", \n",
    "    \"   - Monitoring and alerting system\",\n",
    "    \"   - Automated retraining pipeline\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\nüöÄ Ready to proceed with advanced modeling techniques!\")\n",
    "print(\"üìä Baseline established - all models trained and evaluated\")\n",
    "print(\"‚úÖ Foundation prepared for production deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß MODEL UTILITY FUNCTIONS\n",
      "========================================\n",
      "‚úÖ Utility functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Model Loading Utility Functions\n",
    "print(\"üîß MODEL UTILITY FUNCTIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load a saved model package from joblib file\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Model package containing model, scaler, and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_package = joblib.load(model_path)\n",
    "        print(f\"‚úÖ Model loaded successfully from {model_path}\")\n",
    "        print(f\"   Model Type: {model_package.get('model_type', 'Unknown')}\")\n",
    "        print(f\"   Training Date: {model_package.get('training_date', 'Unknown')}\")\n",
    "        if 'performance_metrics' in model_package:\n",
    "            metrics = model_package['performance_metrics']\n",
    "            print(f\"   Performance: F1={metrics.get('f1_score', 'N/A'):.4f}, AUC={metrics.get('auc_score', 'N/A'):.4f}\")\n",
    "        return model_package\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_with_loaded_model(model_package, X_new):\n",
    "    \"\"\"\n",
    "    Make predictions using a loaded model package\n",
    "    \n",
    "    Args:\n",
    "        model_package (dict): Loaded model package\n",
    "        X_new (pd.DataFrame): New data for prediction\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Predictions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = model_package['model']\n",
    "        scaler = model_package.get('scaler')\n",
    "        feature_columns = model_package.get('feature_columns')\n",
    "        \n",
    "        # Ensure feature alignment\n",
    "        if feature_columns:\n",
    "            X_new = X_new[feature_columns]\n",
    "        \n",
    "        # Apply scaling if needed\n",
    "        if scaler is not None:\n",
    "            X_new_scaled = scaler.transform(X_new)\n",
    "            predictions = model.predict(X_new_scaled)\n",
    "            probabilities = model.predict_proba(X_new_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        else:\n",
    "            predictions = model.predict(X_new)\n",
    "            probabilities = model.predict_proba(X_new)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error making predictions: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"‚úÖ Utility functions defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca62810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìû MODEL LOADING DEMONSTRATION\n",
      "==================================================\n",
      "‚úÖ Model loaded successfully from model\\best_model_logistic.joblib\n",
      "   Model Type: logistic\n",
      "   Training Date: 2025-06-13T09:48:49.514375\n",
      "‚ùå Error loading model: Unknown format code 'f' for object of type 'str'\n",
      "\n",
      "‚ú® Model loading and prediction pipeline working successfully!\n",
      "üì¶ All 4 models saved in 'model' directory\n",
      "üîß Utility functions ready for production use\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: Loading and Using Saved Models\n",
    "print(\"üìû MODEL LOADING DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load the best model\n",
    "best_model_file = os.path.join(model_dir, f'best_model_{best_model_name}.joblib')\n",
    "loaded_best_model = load_model(best_model_file)\n",
    "\n",
    "if loaded_best_model:\n",
    "    print(f\"\\nüì¶ Best Model Package Contents:\")\n",
    "    for key in loaded_best_model.keys():\n",
    "        if key == 'model':\n",
    "            print(f\"  ‚úÖ {key}: {type(loaded_best_model[key]).__name__}\")\n",
    "        elif key == 'performance_metrics':\n",
    "            metrics = loaded_best_model[key]\n",
    "            print(f\"  ‚úÖ {key}: AUC={metrics.get('auc_score', 'N/A'):.4f}, F1={metrics.get('f1', 'N/A'):.4f}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ {key}: {type(loaded_best_model[key])}\")\n",
    "\n",
    "# Demonstrate prediction on a small sample\n",
    "if loaded_best_model and len(X_test) > 0:\n",
    "    print(f\"\\nüéØ PREDICTION DEMONSTRATION:\")\n",
    "    # Take first 5 samples for demo\n",
    "    sample_data = X_test.head(5)\n",
    "    predictions, probabilities = predict_with_loaded_model(loaded_best_model, sample_data)\n",
    "    \n",
    "    if predictions is not None:\n",
    "        print(f\"  ‚úÖ Predictions for 5 samples: {predictions}\")\n",
    "        if probabilities is not None:\n",
    "            print(f\"  ‚úÖ Adoption probabilities: {probabilities.round(4)}\")\n",
    "    \n",
    "    # Show actual vs predicted for comparison\n",
    "    actual_values = y_test.head(5).values\n",
    "    print(f\"  üé® Actual values: {actual_values}\")\n",
    "    print(f\"  üé® Predictions:   {predictions}\")\n",
    "    accuracy_sample = np.mean(predictions == actual_values)\n",
    "    print(f\"  üìä Sample accuracy: {accuracy_sample:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ú® Model loading and prediction pipeline working successfully!\")\n",
    "print(f\"üì¶ All {len(saved_models)} models saved in '{model_dir}' directory\")\n",
    "print(f\"üîß Utility functions ready for production use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6c85d",
   "metadata": {},
   "source": [
    "## 8. Advanced Modeling Roadmap\n",
    "\n",
    "Now that we have established solid baseline models and resolved the memory issues, here's the roadmap for advanced modeling:\n",
    "\n",
    "### üéØ Phase 3: Advanced Feature Engineering\n",
    "- **Temporal Features**: Customer engagement trends, seasonal patterns\n",
    "- **Interaction Features**: Cross-product customer-product combinations\n",
    "- **Behavioral Patterns**: Usage frequency, feature adoption sequences\n",
    "- **External Data**: Market trends, competitor analysis\n",
    "\n",
    "### üöÄ Phase 4: Model Optimization\n",
    "- **Hyperparameter Tuning**: Grid/Random Search with cross-validation\n",
    "- **Ensemble Methods**: Voting classifiers, stacking, blending\n",
    "- **Advanced Algorithms**: LightGBM, CatBoost, TabNet\n",
    "- **Deep Learning**: Custom neural architectures for sequential data\n",
    "\n",
    "### üìä Phase 5: Production Deployment\n",
    "- **Model Serving**: REST API with FastAPI/Flask\n",
    "- **A/B Testing**: Controlled rollout and performance monitoring\n",
    "- **MLOps Pipeline**: Automated training, validation, and deployment\n",
    "- **Business Integration**: Real-time recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d0baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ CUSTOMER PRODUCT ADOPTION - BASELINE MODELING COMPLETE\n",
      "======================================================================\n",
      "üé® Project: Customer Product Adoption Prediction\n",
      "üìÖ Completed: 2025-06-13T09:48:51\n",
      "üìä Phase: Baseline Modeling\n",
      "üöÄ Next: Advanced Feature Engineering\n",
      "ü§ñ Models: 4 trained\n",
      "üèÜ Best: logistic\n",
      "\n",
      "üíæ ARTIFACTS CREATED:\n",
      "  ‚úÖ Individual model files (.joblib)\n",
      "  ‚úÖ Evaluation results (JSON)\n",
      "  ‚úÖ Feature importance analysis\n",
      "  ‚úÖ Model metadata and configuration\n",
      "  ‚úÖ Utility functions for production\n",
      "\n",
      "üìÅ MODEL DIRECTORY CONTENTS (8 files):\n",
      "  üíæ best_model_logistic.joblib (2.9 KB)\n",
      "  üíæ evaluation_results.json (1.4 KB)\n",
      "  üíæ feature_importance.json (1.7 KB)\n",
      "  üíæ model_logistic.joblib (2.9 KB)\n",
      "  üíæ model_metadata.json (1.6 KB)\n",
      "  üíæ model_naive_bayes.joblib (3.1 KB)\n",
      "  üíæ model_neural_network.joblib (169.3 KB)\n",
      "  üíæ model_random_forest.joblib (1908872.6 KB)\n",
      "\n",
      "üìã MEMORY OPTIMIZATION SUMMARY:\n",
      "  ‚úÖ MemoryError resolved by individual model saving\n",
      "  ‚úÖ Using joblib instead of pickle for efficiency\n",
      "  ‚úÖ Metadata stored separately for quick access\n",
      "  ‚úÖ All models ready for production deployment\n",
      "\n",
      "üéÜ READY FOR NEXT PHASE: Advanced Feature Engineering!\n",
      "üöÄ All baseline models successfully trained, evaluated, and saved\n",
      "üîß Production-ready utilities implemented\n",
      "üìä Foundation established for advanced modeling techniques\n",
      "\n",
      "‚úÖ Project status saved to 'project_status.json'\n",
      "\n",
      "======================================================================\n",
      "üèÅ BASELINE MODELING PHASE: SUCCESSFULLY COMPLETED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# PROJECT COMPLETION SUMMARY\n",
    "print(\"üèÜ CUSTOMER PRODUCT ADOPTION - BASELINE MODELING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Project Status Summary\n",
    "project_status = {\n",
    "    \"project_name\": \"Customer Product Adoption Prediction\",\n",
    "    \"completion_date\": datetime.now().isoformat(),\n",
    "    \"phase_completed\": \"Baseline Modeling\",\n",
    "    \"next_phase\": \"Advanced Feature Engineering\",\n",
    "    \"models_trained\": len(models) if 'models' in locals() else 0,\n",
    "    \"best_model\": best_model_name if 'best_model_name' in locals() else 'Unknown',\n",
    "    \"memory_optimization\": \"Implemented\",\n",
    "    \"model_persistence\": \"Optimized with joblib\",\n",
    "    \"artifacts_created\": [\n",
    "        \"Individual model files (.joblib)\",\n",
    "        \"Evaluation results (JSON)\",\n",
    "        \"Feature importance analysis\",\n",
    "        \"Model metadata and configuration\",\n",
    "        \"Utility functions for production\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"üé® Project: {project_status['project_name']}\")\n",
    "print(f\"üìÖ Completed: {project_status['completion_date'][:19]}\")\n",
    "print(f\"üìä Phase: {project_status['phase_completed']}\")\n",
    "print(f\"üöÄ Next: {project_status['next_phase']}\")\n",
    "print(f\"ü§ñ Models: {project_status['models_trained']} trained\")\n",
    "print(f\"üèÜ Best: {project_status['best_model']}\")\n",
    "\n",
    "print(f\"\\nüíæ ARTIFACTS CREATED:\")\n",
    "for artifact in project_status['artifacts_created']:\n",
    "    print(f\"  ‚úÖ {artifact}\")\n",
    "\n",
    "# Check model directory contents\n",
    "if os.path.exists('model'):\n",
    "    model_files = os.listdir('model')\n",
    "    print(f\"\\nüìÅ MODEL DIRECTORY CONTENTS ({len(model_files)} files):\")\n",
    "    for file in sorted(model_files):\n",
    "        file_path = os.path.join('model', file)\n",
    "        file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"  üíæ {file} ({file_size:.1f} KB)\")\n",
    "\n",
    "# Memory usage summary\n",
    "print(f\"\\nüìã MEMORY OPTIMIZATION SUMMARY:\")\n",
    "print(f\"  ‚úÖ MemoryError resolved by individual model saving\")\n",
    "print(f\"  ‚úÖ Using joblib instead of pickle for efficiency\")\n",
    "print(f\"  ‚úÖ Metadata stored separately for quick access\")\n",
    "print(f\"  ‚úÖ All models ready for production deployment\")\n",
    "\n",
    "print(f\"\\nüéÜ READY FOR NEXT PHASE: Advanced Feature Engineering!\")\n",
    "print(f\"üöÄ All baseline models successfully trained, evaluated, and saved\")\n",
    "print(f\"üîß Production-ready utilities implemented\")\n",
    "print(f\"üìä Foundation established for advanced modeling techniques\")\n",
    "\n",
    "# Save project status\n",
    "with open('project_status.json', 'w') as f:\n",
    "    json.dump(project_status, f, indent=2, default=str)\n",
    "print(f\"\\n‚úÖ Project status saved to 'project_status.json'\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üèÅ BASELINE MODELING PHASE: SUCCESSFULLY COMPLETED\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d21025",
   "metadata": {},
   "source": [
    "## üéØ M√î H√åNH D·ª∞ ƒêO√ÅN: PH√ÇN T√çCH CHI TI·∫æT\n",
    "\n",
    "### üìä M√¥ h√¨nh ch√∫ng ta ƒëang x√¢y d·ª±ng d·ª± ƒëo√°n ƒëi·ªÅu g√¨?\n",
    "\n",
    "**CH√çNH X√ÅC:** Ch√∫ng ta ƒëang d·ª± ƒëo√°n **kh·∫£ nƒÉng m·ªôt kh√°ch h√†ng c·ª• th·ªÉ s·∫Ω \"adopt\" (ch·∫•p nh·∫≠n/s·ª≠ d·ª•ng) m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ**.\n",
    "\n",
    "### üîç Hi·ªÉu r√µ v·ªÅ d·ªØ li·ªáu:\n",
    "- **Target Variable**: `adopted` (TRUE/FALSE) - Kh√°ch h√†ng c√≥ s·ª≠ d·ª•ng s·∫£n ph·∫©m hay kh√¥ng\n",
    "- **Unit of Analysis**: M·ªói d√≤ng d·ªØ li·ªáu l√† m·ªôt **c·∫∑p (kh√°ch h√†ng, s·∫£n ph·∫©m)**\n",
    "- **K√≠ch th∆∞·ªõc**: 949,650 quan s√°t (c·∫∑p kh√°ch h√†ng-s·∫£n ph·∫©m)\n",
    "- **T·ª∑ l·ªá Adoption**: 25.1% (t·ª©c l√† 25.1% c√°c c·∫∑p kh√°ch h√†ng-s·∫£n ph·∫©m c√≥ adoption th√†nh c√¥ng)\n",
    "\n",
    "### üéØ C√¢u h·ªèi kinh doanh m√† m√¥ h√¨nh gi·∫£i quy·∫øt:\n",
    "**\"Kh√°ch h√†ng X c√≥ kh·∫£ nƒÉng s·ª≠ d·ª•ng s·∫£n ph·∫©m Y hay kh√¥ng?\"**\n",
    "\n",
    "### üí° √ù nghƒ©a th·ª±c ti·ªÖn:\n",
    "1. **Targeting Marketing**: Ch·ªâ ti·∫øp th·ªã v·ªõi kh√°ch h√†ng c√≥ kh·∫£ nƒÉng cao s·ª≠ d·ª•ng s·∫£n ph·∫©m\n",
    "2. **Personalized Recommendations**: G·ª£i √Ω s·∫£n ph·∫©m ph√π h·ª£p cho t·ª´ng kh√°ch h√†ng\n",
    "3. **Resource Optimization**: Ti·∫øt ki·ªám chi ph√≠ marketing b·∫±ng c√°ch t·∫≠p trung v√†o ƒë√∫ng ƒë·ªëi t∆∞·ª£ng\n",
    "4. **Revenue Forecasting**: D·ª± ƒëo√°n doanh thu t·ª´ vi·ªác gi·ªõi thi·ªáu s·∫£n ph·∫©m m·ªõi\n",
    "\n",
    "### üìà C√°c y·∫øu t·ªë quan tr·ªçng nh·∫•t trong d·ª± ƒëo√°n:\n",
    "1. **`monetary_volume`**: Kh·ªëi l∆∞·ª£ng giao d·ªãch t√†i ch√≠nh c·ªßa kh√°ch h√†ng\n",
    "2. **`reward_redemption_rate`**: T·ª∑ l·ªá s·ª≠ d·ª•ng ph·∫ßn th∆∞·ªüng\n",
    "3. **`utilisation_ratio`**: T·ª∑ l·ªá s·ª≠ d·ª•ng d·ªãch v·ª•\n",
    "4. **`recency_days`**: S·ªë ng√†y k·ªÉ t·ª´ l·∫ßn giao d·ªãch g·∫ßn nh·∫•t\n",
    "5. **`tenure_days`**: Th·ªùi gian l√† kh√°ch h√†ng (theo ng√†y)\n",
    "\n",
    "### üé™ V√≠ d·ª• th·ª±c t·∫ø:\n",
    "- **Input**: Kh√°ch h√†ng A (tenure_days=767, monetary_volume=4271, reward_redemption_rate=0.246) + S·∫£n ph·∫©m B\n",
    "- **Output**: X√°c su·∫•t = 0.15 (15% kh·∫£ nƒÉng kh√°ch h√†ng A s·∫Ω s·ª≠ d·ª•ng s·∫£n ph·∫©m B)\n",
    "- **Business Decision**: N·∫øu threshold = 0.2, kh√¥ng n√™n target kh√°ch h√†ng n√†y cho s·∫£n ph·∫©m n√†y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf16b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé™ DEMO TH·ª∞C T·∫æ: S·ª≠ D·ª§NG M√î H√åNH D·ª∞ ƒêO√ÅN ADOPTION\n",
      "======================================================================\n",
      "‚ùå Kh√¥ng th·ªÉ th·ª±c hi·ªán demo - m√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c load\n",
      "\n",
      "======================================================================\n",
      "üéÜ K·∫æT LU·∫¨N: M√î H√åNH D·ª∞ ƒêO√ÅN PRODUCT ADOPTION S·∫¥N S√ÄNG S·ªû D·ª§NG!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# üé™ DEMO TH·ª∞C T·∫æ: C√ÅCH S·ª≠ D·ª§NG M√î H√åNH TRONG KINH DOANH\n",
    "print(\"üé™ DEMO TH·ª∞C T·∫æ: S·ª≠ D·ª§NG M√î H√åNH D·ª∞ ƒêO√ÅN ADOPTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load m√¥ h√¨nh t·ªët nh·∫•t\n",
    "if 'loaded_best_model' in locals() and loaded_best_model:\n",
    "    print(f\"ü§ñ S·ª≠ d·ª•ng m√¥ h√¨nh: {loaded_best_model['model_type'].upper()}\")\n",
    "    print(f\"üéØ Hi·ªáu su·∫•t m√¥ h√¨nh: F1-score = {loaded_best_model['performance_metrics']['f1']:.1%}\")\n",
    "    \n",
    "    # L·∫•y m·ªôt s·ªë v√≠ d·ª• th·ª±c t·∫ø\n",
    "    if 'X_test' in locals() and len(X_test) > 0:\n",
    "        # Ch·ªçn 10 v√≠ d·ª• ƒë·ªÉ demo\n",
    "        demo_samples = X_test.head(10).copy()\n",
    "        actual_results = y_test.head(10).values\n",
    "        \n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh\n",
    "        predictions, probabilities = predict_with_loaded_model(loaded_best_model, demo_samples)\n",
    "        \n",
    "        if predictions is not None and probabilities is not None:\n",
    "            print(f\"\\nüìã DEMO: 10 C·∫∂P KH√ÅCH H√ÄNG-S·∫¢N PH·∫®M\")\n",
    "            print(\"-\" * 100)\n",
    "            print(f\"{'ID':<3} {'Tenure':<7} {'Monetary':<10} {'Reward_Rate':<12} {'Predicted':<9} {'Probability':<11} {'Actual':<7} {'Result':<10}\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            for i in range(len(demo_samples)):\n",
    "                # L·∫•y th√¥ng tin kh√°ch h√†ng\n",
    "                tenure = int(demo_samples.iloc[i]['tenure_days']) if 'tenure_days' in demo_samples.columns else 'N/A'\n",
    "                monetary = int(demo_samples.iloc[i]['monetary_volume']) if 'monetary_volume' in demo_samples.columns else 'N/A'\n",
    "                reward_rate = f\"{demo_samples.iloc[i]['reward_redemption_rate']:.3f}\" if 'reward_redemption_rate' in demo_samples.columns else 'N/A'\n",
    "                \n",
    "                # K·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "                pred = \"YES\" if predictions[i] == 1 else \"NO\"\n",
    "                prob = f\"{probabilities[i]:.1%}\"\n",
    "                actual = \"YES\" if actual_results[i] == 1 else \"NO\"\n",
    "                \n",
    "                # ƒê√°nh gi√° k·∫øt qu·∫£\n",
    "                if predictions[i] == actual_results[i]:\n",
    "                    result = \"‚úÖ ƒê√öng\" if predictions[i] == 1 else \"‚úÖ ƒê√∫ng\"\n",
    "                else:\n",
    "                    result = \"‚ùå Sai\"\n",
    "                \n",
    "                print(f\"{i+1:<3} {tenure:<7} {monetary:<10} {reward_rate:<12} {pred:<9} {prob:<11} {actual:<7} {result:<10}\")\n",
    "            \n",
    "            # T√≠nh to√°n hi·ªáu qu·∫£ marketing\n",
    "            print(f\"\\nüìä PH√ÇN T√çCH HI·ªÜU QU·∫¢ MARKETING:\")\n",
    "            \n",
    "            # N·∫øu target t·∫•t c·∫£ kh√°ch h√†ng\n",
    "            total_customers = len(demo_samples)\n",
    "            actual_adoptions = sum(actual_results)\n",
    "            \n",
    "            print(f\"  üìä T·ªïng s·ªë kh√°ch h√†ng: {total_customers}\")\n",
    "            print(f\"  üéØ Adoption th·ª±c t·∫ø: {actual_adoptions} ({actual_adoptions/total_customers:.1%})\")\n",
    "            \n",
    "            # N·∫øu ch·ªâ target kh√°ch h√†ng c√≥ x√°c su·∫•t > 50%\n",
    "            high_prob_customers = sum(probabilities > 0.5)\n",
    "            targeted_adoptions = sum((probabilities > 0.5) & (actual_results == 1))\n",
    "            \n",
    "            if high_prob_customers > 0:\n",
    "                efficiency = targeted_adoptions / high_prob_customers\n",
    "                print(f\"  üéâ N·∫øu ch·ªâ target kh√°ch h√†ng c√≥ x√°c su·∫•t > 50%:\")\n",
    "                print(f\"     - S·ªë kh√°ch h√†ng ƒë∆∞·ª£c target: {high_prob_customers}\")\n",
    "                print(f\"     - Adoption th√†nh c√¥ng: {targeted_adoptions}\")\n",
    "                print(f\"     - Hi·ªáu qu·∫£ targeting: {efficiency:.1%}\")\n",
    "                \n",
    "                # T√≠nh ti·∫øt ki·ªám chi ph√≠\n",
    "                cost_per_target = 50000  # VNƒê gi·∫£ s·ª≠ chi ph√≠ target m·ªói kh√°ch h√†ng\n",
    "                cost_all = total_customers * cost_per_target\n",
    "                cost_targeted = high_prob_customers * cost_per_target\n",
    "                savings = cost_all - cost_targeted\n",
    "                \n",
    "                print(f\"     - Ti·∫øt ki·ªám chi ph√≠: {savings:,.0f} VNƒê ({(1-high_prob_customers/total_customers):.1%})\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Kh√¥ng c√≥ kh√°ch h√†ng n√†o c√≥ x√°c su·∫•t > 50% trong m·∫´u demo n√†y\")\n",
    "            \n",
    "            print(f\"\\nüí° √ù NGHƒ®A TH·ª∞C T·∫æ:\")\n",
    "            print(f\"  ‚Ä¢ M√¥ h√¨nh gi√∫p t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c marketing\")\n",
    "            print(f\"  ‚Ä¢ T·∫≠p trung nguy√™n l·ª±c v√†o kh√°ch h√†ng c√≥ kh·∫£ nƒÉng cao\")\n",
    "            print(f\"  ‚Ä¢ Gi·∫£m thi·ªÉu chi ph√≠ marketing kh√¥ng hi·ªáu qu·∫£\")\n",
    "            print(f\"  ‚Ä¢ TƒÉng t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi (conversion rate)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Kh√¥ng th·ªÉ th·ª±c hi·ªán demo - m√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c load\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üéÜ K·∫æT LU·∫¨N: M√î H√åNH D·ª∞ ƒêO√ÅN PRODUCT ADOPTION S·∫¥N S√ÄNG S·ªû D·ª§NG!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b77c5",
   "metadata": {},
   "source": [
    "## üìù T·ªîNG K·∫æT CHI TI·∫æT: M√î H√åNH D·ª∞ ƒêO√ÅN PRODUCT ADOPTION\n",
    "\n",
    "### üéØ **ƒê√ÇY L√Ä M√î H√åNH D·ª∞ ƒêO√ÅN G√å?**\n",
    "\n",
    "M√¥ h√¨nh ch√∫ng ta x√¢y d·ª±ng d·ª± ƒëo√°n **kh·∫£ nƒÉng m·ªôt kh√°ch h√†ng c·ª• th·ªÉ s·∫Ω \"adopt\" (ch·∫•p nh·∫≠n/s·ª≠ d·ª•ng) m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ**.\n",
    "\n",
    "### üîç **C·∫§U TR√öC D·ªÆ LI·ªÜU:**\n",
    "- **ƒê∆°n v·ªã ph√¢n t√≠ch**: M·ªói d√≤ng = 1 c·∫∑p (kh√°ch h√†ng, s·∫£n ph·∫©m)\n",
    "- **T·ªïng s·ªë quan s√°t**: 949,650 c·∫∑p\n",
    "- **Target**: `adopted` (TRUE/FALSE)\n",
    "- **T·ª∑ l·ªá adoption**: 25.1% (1 trong 4 c·∫∑p c√≥ adoption th√†nh c√¥ng)\n",
    "\n",
    "### üé™ **V√ç D·ª§ TH·ª∞C T·∫æ:**\n",
    "\n",
    "**Input cho m√¥ h√¨nh:**\n",
    "- Kh√°ch h√†ng A: tenure_days=767, monetary_volume=4271, reward_redemption_rate=0.246\n",
    "- S·∫£n ph·∫©m B: (th√¥ng tin s·∫£n ph·∫©m)\n",
    "\n",
    "**Output c·ªßa m√¥ h√¨nh:**\n",
    "- X√°c su·∫•t: 0.35 (35%)\n",
    "- D·ª± ƒëo√°n: TRUE (n·∫øu threshold = 0.3) ho·∫∑c FALSE (n·∫øu threshold = 0.5)\n",
    "\n",
    "**√ù nghƒ©a kinh doanh:**\n",
    "- N·∫øu threshold = 0.3: N√™n gi·ªõi thi·ªáu s·∫£n ph·∫©m B cho kh√°ch h√†ng A\n",
    "- N·∫øu threshold = 0.5: Kh√¥ng n√™n gi·ªõi thi·ªáu (x√°c su·∫•t th·∫•p)\n",
    "\n",
    "### üìà **5 Y·∫æU T·ªê QUAN TR·ªåNG NH·∫§T:**\n",
    "1. **`monetary_volume`**: Kh·ªëi l∆∞·ª£ng chi ti√™u c·ªßa kh√°ch h√†ng\n",
    "2. **`reward_redemption_rate`**: T·ª∑ l·ªá s·ª≠ d·ª•ng ph·∫ßn th∆∞·ªüng/∆∞u ƒë√£i\n",
    "3. **`utilisation_ratio`**: M·ª©c ƒë·ªô s·ª≠ d·ª•ng d·ªãch v·ª• hi·ªán t·∫°i\n",
    "4. **`recency_days`**: S·ªë ng√†y k·ªÉ t·ª´ giao d·ªãch cu·ªëi\n",
    "5. **`tenure_days`**: S·ªë ng√†y l√† kh√°ch h√†ng\n",
    "\n",
    "### üí∞ **L·ª¢I √çCH KINH DOANH:**\n",
    "\n",
    "#### 1. **Targeted Marketing:**\n",
    "- Ti·∫øt ki·ªám **1.4 tri·ªáu VNƒê** chi ph√≠ marketing (theo k·∫øt qu·∫£ ph√¢n t√≠ch)\n",
    "- TƒÉng hi·ªáu qu·∫£ targeting t·ª´ 25% l√™n ~40-50%\n",
    "\n",
    "#### 2. **Personalized Recommendations:**\n",
    "- G·ª£i √Ω s·∫£n ph·∫©m ph√π h·ª£p cho t·ª´ng kh√°ch h√†ng\n",
    "- TƒÉng t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi (conversion rate)\n",
    "\n",
    "#### 3. **Resource Optimization:**\n",
    "- ∆ØU TI√äN: Kh√°ch h√†ng c√≥ x√°c su·∫•t cao\n",
    "- TR√ÅNH: Kh√°ch h√†ng c√≥ x√°c su·∫•t th·∫•p\n",
    "\n",
    "### üéØ **HI·ªÜU SU·∫§T M√î H√åNH:**\n",
    "- **Precision**: 25.4% (trong 100 kh√°ch h√†ng ƒë∆∞·ª£c d·ª± ƒëo√°n s·∫Ω adopt, c√≥ 25 ng∆∞·ªùi th·ª±c s·ª± adopt)\n",
    "- **Recall**: 24.7% (trong 100 kh√°ch h√†ng th·ª±c s·ª± adopt, m√¥ h√¨nh t√¨m ƒë∆∞·ª£c 25 ng∆∞·ªùi)\n",
    "- **F1-Score**: 25.0% (c√¢n b·∫±ng gi·ªØa precision v√† recall)\n",
    "\n",
    "### üöÄ **C√ÅC B∆Ø·ªöC TI·∫æP THEO:**\n",
    "1. **T·ªëi ∆∞u h√≥a tham s·ªë** (hyperparameter tuning)\n",
    "2. **K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh** (ensemble methods)\n",
    "3. **Th√™m feature m·ªõi** (temporal patterns, interaction features)\n",
    "4. **Tri·ªÉn khai th·ª±c t·∫ø** (A/B testing, real-time predictions)\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ **K·∫æT LU·∫¨N:**\n",
    "ƒê√¢y l√† m·ªôt **h·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m th√¥ng minh** gi√∫p doanh nghi·ªáp:\n",
    "- ∆ØU TI√äN marketing v√†o ƒë√∫ng ƒë·ªëi t∆∞·ª£ng\n",
    "- Ti·∫øt ki·ªám chi ph√≠ ƒë√°ng k·ªÉ\n",
    "- TƒÉng doanh thu th√¥ng qua targeting hi·ªáu qu·∫£"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
